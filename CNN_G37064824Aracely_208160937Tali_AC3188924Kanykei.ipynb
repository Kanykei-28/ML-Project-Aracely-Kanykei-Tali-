{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **<font color='greee'>Project  </font>** **<font color='pink'> Alzheimer’s MRI images – Extracting numerical and statistical features for classification  </font>**\n",
        "\n",
        "<font color='orange'>Professor: </font> Osnat Bar-Shira\n",
        "\n",
        "<font color='orange'>TA: </font> Benjamin Menashe\n",
        "\n",
        "<font color='orange'>Students: </font>\n",
        "\n",
        "Aracely Gutiérrez Lomelí G37064824\n",
        "\n",
        "Tali Rozenson 208160937\n",
        "\n",
        "Kanykei Mairambekova AC3188924\n",
        "\n",
        "<font color='pink'>Note: </font>\n",
        "\n",
        "The analysis of results is done in the report to avoid repeating descriptions both in the document and in the coding notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "uoX4BfnWN2Do"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='orange'>0. Imports</font>"
      ],
      "metadata": {
        "id": "2opip8QJOVAJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTuxOGapWPuH",
        "outputId": "02d72d2f-db48-4a1f-9ba3-562c28dc5df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# For creating training and test drive folders\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Using Google drive as storage\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Pytorch for neural networks\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# For time recording\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='orange'>1. First trial: Downsampling</font>\n",
        "\n",
        "Drive folders for train and test set in a ratio of 80% and 20%, respectively.\n",
        "\n",
        "Classes are imbalanced. It was decided to downsample every label into the minimum amount of images in any of the classes, 64 images for the moderate demented label. Therefore, the first trial only included 64 images per label: 51 for training and 13 for testing."
      ],
      "metadata": {
        "id": "F2vVIrZbmaXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>1.1 Creating train drive folders for each label</font>"
      ],
      "metadata": {
        "id": "yXVLotwkPqka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to folders\n",
        "mild_path = '/content/drive/MyDrive/Dataset/Mild_Demented'\n",
        "moderate_path = '/content/drive/MyDrive/Dataset/Moderate_Demented'\n",
        "non_path = '/content/drive/MyDrive/Dataset/Non_Demented'\n",
        "very_mild_path = '/content/drive/MyDrive/Dataset/Very_Mild_Demented'\n",
        "\n",
        "# Function to randomly select and copy 51 images from a folder\n",
        "def select_random_images(source_path, dest_path, num_images=51):\n",
        "    file_list = os.listdir(source_path)\n",
        "    selected_files = random.sample(file_list, min(num_images, len(file_list)))\n",
        "\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    os.makedirs(dest_path, exist_ok=True)\n",
        "\n",
        "    # Copy selected files to the destination folder\n",
        "    for file_name in selected_files:\n",
        "        source_file_path = os.path.join(source_path, file_name)\n",
        "        dest_file_path = os.path.join(dest_path, file_name)\n",
        "        shutil.copy2(source_file_path, dest_file_path)\n",
        "\n",
        "# Randomly select and copy 51 images from each folder\n",
        "select_random_images(mild_path, '/content/drive/MyDrive/Dataset/Train/Mild')\n",
        "select_random_images(moderate_path, '/content/drive/MyDrive/Dataset/Train/Moderate')\n",
        "select_random_images(non_path, '/content/drive/MyDrive/Dataset/Train/Non')\n",
        "select_random_images(very_mild_path, '/content/drive/MyDrive/Dataset/Train/Very_Mild')"
      ],
      "metadata": {
        "id": "NUIPC44NavQm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>1.2 Creating test drive folders for each label</font>"
      ],
      "metadata": {
        "id": "3UGxRc-lP5-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to folders\n",
        "mild_path = '/content/drive/MyDrive/Dataset/Mild_Demented'\n",
        "moderate_path = '/content/drive/MyDrive/Dataset/Moderate_Demented'\n",
        "non_path = '/content/drive/MyDrive/Dataset/Non_Demented'\n",
        "very_mild_path = '/content/drive/MyDrive/Dataset/Very_Mild_Demented'\n",
        "\n",
        "# Function to randomly select and copy 13 images from a folder\n",
        "def select_random_images(source_path, dest_path, num_images=13):\n",
        "    file_list = os.listdir(source_path)\n",
        "    selected_files = random.sample(file_list, min(num_images, len(file_list)))\n",
        "\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    os.makedirs(dest_path, exist_ok=True)\n",
        "\n",
        "    # Copy selected files to the destination folder\n",
        "    for file_name in selected_files:\n",
        "        source_file_path = os.path.join(source_path, file_name)\n",
        "        dest_file_path = os.path.join(dest_path, file_name)\n",
        "        shutil.copy2(source_file_path, dest_file_path)\n",
        "\n",
        "# Randomly select and copy 13 images from each folder\n",
        "select_random_images(mild_path, '/content/drive/MyDrive/Dataset/Test/Mild')\n",
        "select_random_images(moderate_path, '/content/drive/MyDrive/Dataset/Test/Moderate')\n",
        "select_random_images(non_path, '/content/drive/MyDrive/Dataset/Test/Non')\n",
        "select_random_images(very_mild_path, '/content/drive/MyDrive/Dataset/Test/Very_Mild')"
      ],
      "metadata": {
        "id": "rLAmG-OghGdR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>1.3 Transforming images to tensors and normalizing</font>\n",
        "\n",
        "Each pixel is usually scaled to range of 0 to 1. Then, in the normalization step, we would usually prefer a mean of 0 and standard deviation of 1 but another common normalization practice is0.5 as mean and 0.5 as standard deviation."
      ],
      "metadata": {
        "id": "vIkGrXaqR77u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformation for your images\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "gmbCOq2OolzT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>1.4 Defining the labels for the images in train and test sets</font>\n",
        "\n",
        "In the previous cells, we have divided our images by folders containing the name of the label of the pictures. In the next two cells, we define the label of each image as the name of the folder it is contained in.\n",
        "\n",
        "\n",
        "The datasets.ImageFolder class automatically assigns labels based on\n",
        "the subfolder names inside the specified root folder.\n",
        "\n",
        "The batch size is calculates as *Effective batch size = Total samples / Update steps* and since we have very few samples in the test set, we might use 6 update steps and a batch size of 2."
      ],
      "metadata": {
        "id": "XzfOoWUjSbbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the \"Train\" folder\n",
        "train_root = '/content/drive/MyDrive/Dataset/Train'\n",
        "\n",
        "# Create the ImageFolder dataset\n",
        "train_dataset = datasets.ImageFolder(train_root, transform=transform)\n",
        "\n",
        "# You can use DataLoader to create batches for training\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "u94YIyn1XPkS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the \"Test\" folder\n",
        "test_root = '/content/drive/MyDrive/Dataset/Test'\n",
        "\n",
        "# Create the ImageFolder dataset\n",
        "test_dataset = datasets.ImageFolder(test_root, transform=transform)\n",
        "\n",
        "# You can use DataLoader to create batches for training\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "eo4i19-tmSCM"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>1.5 CNN Model</font>\n",
        "\n",
        "A convolutional neural network was used as the classification model.\n",
        "\n",
        "Although the images are supposed to be grayscale (one input channel), the algorithm detected three as in RGB images, so the CNN model algorithm includes three input channels. Importantly, the number of output channels is just a design choice in the architecture of the model, and the kernel size means the kernel is squared 5x5. The output size for the fully connected layers corresponds to the number of classes (multiclass classification task: 4 labels = mild, moderate, very mild and non-demented)."
      ],
      "metadata": {
        "id": "hZUN9s-cWCqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # First Convolutional Layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5) # nn.Conv2d = Convolutional layers for 2D and 1D data\n",
        "        # Second Convolutional Layer\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        # Fully Connected Layers\n",
        "        self.fc1 = nn.Linear(16 * 29 * 29, 120)  # 16 channels, 29x29 spatial dimensions = Input to the fully connected layers\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 4)  # Output size corresponds to the number of classes (4 = Mild, moderate, very mild demented and nondemented)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First Convolutional Layer with ReLU activation and max pooling\n",
        "        x = F.relu(self.conv1(x)) # size will be reduced by N-F/stride +1 = 128-5/1 + 1 = 124\n",
        "        x = F.max_pool2d(x, 2) #  124/2 = 62\n",
        "        # Second Convolutional Layer with ReLU activation and max pooling\n",
        "        x = F.relu(self.conv2(x)) # 62-5/1 + 1 = 58\n",
        "        x = F.max_pool2d(x, 2) # 58/2 = 29\n",
        "        # Flatten before passing through fully connected layers\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        # Fully Connected Layers with ReLU activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # Output layer (no activation as it's handled by CrossEntropyLoss)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # Exclude batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "metadata": {
        "id": "9N2WVzHvorW9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "cnn_model = SimpleCNN()"
      ],
      "metadata": {
        "id": "ozn7_A__pttP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>1.6 Loss function and optimizer</font>\n",
        "\n",
        "Cross entropy was applied to this task due to the recommended use of multiclass classification. This function is combined with softmax which gives a probability distribution of the classes while the cross entropy function is the loss function measuring how these predicted probabilities guess the true answer."
      ],
      "metadata": {
        "id": "7jxE_iBJXjTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(cnn_model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "umAu1ARy6zzU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>1.7 Implementation of the model</font>\n",
        "By testing and analyzing the number or epochs in previous attempts, it was found that 10 epochs is enough to converge."
      ],
      "metadata": {
        "id": "2vYBC7-yV4sC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "t_start = time.time()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        samples, labels = batch\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = cnn_model(samples)\n",
        "        loss = criterion(y_pred, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Zero the gradients after updating\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(y_pred.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print training accuracy after each epoch\n",
        "    train_accuracy = correct_train / total_train\n",
        "    print(f'Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item():.4f}, Training Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "t_end = time.time()\n",
        "print('Total training time:', t_end - t_start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvTDBzHK75vI",
        "outputId": "7101c812-ed20-45a6-86b1-208cba0a789e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.3858, Training Accuracy: 24.02%\n",
            "Epoch 2/10, Loss: 1.3455, Training Accuracy: 34.80%\n",
            "Epoch 3/10, Loss: 1.3016, Training Accuracy: 46.08%\n",
            "Epoch 4/10, Loss: 0.2853, Training Accuracy: 67.65%\n",
            "Epoch 5/10, Loss: 0.4892, Training Accuracy: 80.88%\n",
            "Epoch 6/10, Loss: 1.1534, Training Accuracy: 88.73%\n",
            "Epoch 7/10, Loss: 0.0368, Training Accuracy: 94.61%\n",
            "Epoch 8/10, Loss: 0.0153, Training Accuracy: 99.02%\n",
            "Epoch 9/10, Loss: 0.0004, Training Accuracy: 100.00%\n",
            "Epoch 10/10, Loss: 0.0000, Training Accuracy: 100.00%\n",
            "Total training time: 63.22462725639343\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='orange'>2. Second trial: Changing the loss function - Focal loss</font>"
      ],
      "metadata": {
        "id": "nYZ5r9xNYmKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Focal loss was used because it is said to encourage the model to learn on misclassified samples, and reduce the impact of the overrepresentation of a certain class (Niyaz, 2023)"
      ],
      "metadata": {
        "id": "HlkpHwKpagtr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        ce_loss = F.cross_entropy(input, target, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            focal_loss = self.alpha * focal_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss"
      ],
      "metadata": {
        "id": "MztRvym0_Wfm"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_focal = FocalLoss(gamma=2, alpha=None, reduction='mean')\n",
        "optimizer=torch.optim.Adam(cnn_model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "UMDeep7atLe5"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "t_start = time.time()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        samples, labels = batch\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = cnn_model(samples)\n",
        "        loss = criterion_focal(y_pred, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Zero the gradients after updating\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(y_pred.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print training accuracy after each epoch\n",
        "    train_accuracy = correct_train / total_train\n",
        "    print(f'Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item():.4f}, Training Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "t_end = time.time()\n",
        "print('Total training time:', t_end - t_start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1E8eNJ_tU27",
        "outputId": "c859d6e1-7783-4a6e-f170-7138a66b5b21"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.3716, Training Accuracy: 55.88%\n",
            "Epoch 2/10, Loss: 0.0311, Training Accuracy: 66.67%\n",
            "Epoch 3/10, Loss: 0.7939, Training Accuracy: 77.45%\n",
            "Epoch 4/10, Loss: 0.1614, Training Accuracy: 82.35%\n",
            "Epoch 5/10, Loss: 0.0276, Training Accuracy: 86.27%\n",
            "Epoch 6/10, Loss: 0.0005, Training Accuracy: 94.12%\n",
            "Epoch 7/10, Loss: 0.0031, Training Accuracy: 98.53%\n",
            "Epoch 8/10, Loss: 0.0000, Training Accuracy: 100.00%\n",
            "Epoch 9/10, Loss: 0.0096, Training Accuracy: 100.00%\n",
            "Epoch 10/10, Loss: 0.0050, Training Accuracy: 100.00%\n",
            "Total training time: 56.176963567733765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='orange'>3. Third trial: Varying parameters in CNN model  - Drop out</font>\n",
        "Dropout was used to prevent overfitting"
      ],
      "metadata": {
        "id": "xSR70gC7cIQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNNWithDropout(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNWithDropout, self).__init__()\n",
        "        # First Convolutional Layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n",
        "        # Second Convolutional Layer\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        # Fully Connected Layers with Dropout\n",
        "        self.fc1 = nn.Linear(16 * 29 * 29, 120)\n",
        "        self.dropout1 = nn.Dropout(0.5)  # Adjust dropout probability as needed\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc3 = nn.Linear(84, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout1(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # Exclude batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n"
      ],
      "metadata": {
        "id": "reVVVxLkBQqx"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "cnn_dropout_model = CNNWithDropout()"
      ],
      "metadata": {
        "id": "3tH7xwoiCN0a"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 10\n",
        "t_start = time.time()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        samples, labels = batch\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = cnn_dropout_model(samples)\n",
        "        loss = criterion_focal(y_pred, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Zero the gradients after updating\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(y_pred.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print training accuracy after each epoch\n",
        "    train_accuracy = correct_train / total_train\n",
        "    print(f'Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item():.4f}, Training Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "t_end = time.time()\n",
        "print('Total training time:', t_end - t_start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68jCmPS_Cvsu",
        "outputId": "162ba4e0-aec0-4a6a-980f-48279accde91"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.8238, Training Accuracy: 25.49%\n",
            "Epoch 2/10, Loss: 0.7807, Training Accuracy: 26.47%\n",
            "Epoch 3/10, Loss: 0.7459, Training Accuracy: 26.47%\n",
            "Epoch 4/10, Loss: 0.7544, Training Accuracy: 23.04%\n",
            "Epoch 5/10, Loss: 0.8679, Training Accuracy: 26.47%\n",
            "Epoch 6/10, Loss: 0.7739, Training Accuracy: 23.53%\n",
            "Epoch 7/10, Loss: 0.7658, Training Accuracy: 22.55%\n",
            "Epoch 8/10, Loss: 0.8895, Training Accuracy: 29.90%\n",
            "Epoch 9/10, Loss: 0.8216, Training Accuracy: 20.59%\n",
            "Epoch 10/10, Loss: 0.8631, Training Accuracy: 22.55%\n",
            "Total training time: 26.403857231140137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='orange'>4. Fourth trial: Using the entire dataset</font>\n",
        "\n",
        "Analyzing the possibility to classify correctly with the entire dataset with focal loss, considering class imbalance.\n",
        "#### <font color='cyan'>4.1 Creating train drive folders for each label</font>"
      ],
      "metadata": {
        "id": "1vbspHaGdKVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to your folders\n",
        "mild_path = '/content/drive/MyDrive/Dataset/Mild_Demented'\n",
        "moderate_path = '/content/drive/MyDrive/Dataset/Moderate_Demented'\n",
        "non_path = '/content/drive/MyDrive/Dataset/Non_Demented'\n",
        "very_mild_path = '/content/drive/MyDrive/Dataset/Very_Mild_Demented'\n",
        "\n",
        "# Function to randomly select and copy 80% of the images from a folder\n",
        "def select_random_images(source_path, dest_path, percentage=0.8):\n",
        "    file_list = os.listdir(source_path)\n",
        "    num_images = int(len(file_list) * percentage)\n",
        "    selected_files = random.sample(file_list, min(num_images, len(file_list)))\n",
        "\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    os.makedirs(dest_path, exist_ok=True)\n",
        "\n",
        "    # Copy selected files to the destination folder\n",
        "    for file_name in selected_files:\n",
        "        source_file_path = os.path.join(source_path, file_name)\n",
        "        dest_file_path = os.path.join(dest_path, file_name)\n",
        "        shutil.copy2(source_file_path, dest_file_path)\n",
        "\n",
        "# Randomly select and copy 80% of the images from each folder\n",
        "select_random_images(mild_path, '/content/drive/MyDrive/Dataset/Large_Train/Mild')\n",
        "select_random_images(moderate_path, '/content/drive/MyDrive/Dataset/Large_Train/Moderate')\n",
        "select_random_images(non_path, '/content/drive/MyDrive/Dataset/Large_Train/Non')\n",
        "select_random_images(very_mild_path, '/content/drive/MyDrive/Dataset/Large_Train/Very_Mild')"
      ],
      "metadata": {
        "id": "YVASF1imDBKU"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>4.2 Creating test drive folders for each label</font>"
      ],
      "metadata": {
        "id": "DGmibcLyd5Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the paths to your folders\n",
        "mild_path = '/content/drive/MyDrive/Dataset/Mild_Demented'\n",
        "moderate_path = '/content/drive/MyDrive/Dataset/Moderate_Demented'\n",
        "non_path = '/content/drive/MyDrive/Dataset/Non_Demented'\n",
        "very_mild_path = '/content/drive/MyDrive/Dataset/Very_Mild_Demented'\n",
        "\n",
        "# Function to randomly select and copy 20% of the images from a folder\n",
        "def select_random_images(source_path, dest_path, percentage=0.2):\n",
        "    file_list = os.listdir(source_path)\n",
        "    num_images = int(len(file_list) * percentage)\n",
        "    selected_files = random.sample(file_list, min(num_images, len(file_list)))\n",
        "\n",
        "    # Create the destination folder if it doesn't exist\n",
        "    os.makedirs(dest_path, exist_ok=True)\n",
        "\n",
        "    # Copy selected files to the destination folder\n",
        "    for file_name in selected_files:\n",
        "        source_file_path = os.path.join(source_path, file_name)\n",
        "        dest_file_path = os.path.join(dest_path, file_name)\n",
        "        shutil.copy2(source_file_path, dest_file_path)\n",
        "\n",
        "# Randomly select and copy 20% of the images from each folder\n",
        "select_random_images(mild_path, '/content/drive/MyDrive/Dataset/Large_Test/Mild')\n",
        "select_random_images(moderate_path, '/content/drive/MyDrive/Dataset/Large_Test/Moderate')\n",
        "select_random_images(non_path, '/content/drive/MyDrive/Dataset/Large_Test/Non')\n",
        "select_random_images(very_mild_path, '/content/drive/MyDrive/Dataset/Large_Test/Very_Mild')"
      ],
      "metadata": {
        "id": "bO1fvk6_GQ5f"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>4.3 Defining the labels for the images in train and test sets</font>"
      ],
      "metadata": {
        "id": "UpTmc605eAAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the \"Train\" folder\n",
        "train_root = '/content/drive/MyDrive/Dataset/Large_Train'\n",
        "\n",
        "# Create the ImageFolder dataset\n",
        "train_dataset = datasets.ImageFolder(train_root, transform=transform)\n",
        "\n",
        "# You can use DataLoader to create batches for training\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True) #Batch sizes= 6400*0.8= 5120 samples/"
      ],
      "metadata": {
        "id": "GnVacq_EJBj2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the \"Test\" folder\n",
        "test_root = '/content/drive/MyDrive/Dataset/Large_Test'\n",
        "\n",
        "# Create the ImageFolder dataset\n",
        "test_dataset = datasets.ImageFolder(test_root, transform=transform)\n",
        "\n",
        "# You can use DataLoader to create batches for training\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True) #Batch sizes= 6400*0.2= 1280 samples/"
      ],
      "metadata": {
        "id": "mSrimZ7rJL7f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>4.4 Defining CNN model</font>"
      ],
      "metadata": {
        "id": "N8Q5Ro0MeDrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # First Convolutional Layer\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5) # nn.Conv2d = Convolutional layers for 2D and 1D data\n",
        "        # Second Convolutional Layer\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5)\n",
        "        # Fully Connected Layers\n",
        "        self.fc1 = nn.Linear(16 * 29 * 29, 120)  # 16 channels, 4x4 spatial dimensions\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 4)  # Output size corresponds to the number of classes (4 = Mild, moderate, very mild demented and nondemented)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First Convolutional Layer with ReLU activation and max pooling\n",
        "        x = F.relu(self.conv1(x)) # size will be reduced by N-F/stride +1 = 128-5/1 + 1 = 124\n",
        "        x = F.max_pool2d(x, 2) #  124/2 = 62\n",
        "        # Second Convolutional Layer with ReLU activation and max pooling\n",
        "        x = F.relu(self.conv2(x)) # 62-5/1 + 1 = 58\n",
        "        x = F.max_pool2d(x, 2) # 58/2 = 29\n",
        "        # Flatten before passing through fully connected layers\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        # Fully Connected Layers with ReLU activation\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # Output layer (no activation as it's handled by CrossEntropyLoss)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # Exclude batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "metadata": {
        "id": "IZwK7Qt2Jguj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>4.5 Instantiating the model</font>"
      ],
      "metadata": {
        "id": "hO-pTR2MeImZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "cnn_model = SimpleCNN()"
      ],
      "metadata": {
        "id": "XOuqlGUvJgul"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>4.6 Defining focal loss</font>"
      ],
      "metadata": {
        "id": "YHG9nkjMecp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None, reduction='mean'):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        ce_loss = F.cross_entropy(input, target, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = (1 - pt) ** self.gamma * ce_loss\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            focal_loss = self.alpha * focal_loss\n",
        "\n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            return focal_loss.sum()\n",
        "        else:\n",
        "            return focal_loss"
      ],
      "metadata": {
        "id": "S9U8tWKHJguo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion_focal = FocalLoss(gamma=2, alpha=None, reduction='mean')\n",
        "optimizer=torch.optim.Adam(cnn_model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "JiDlT-UyJgup"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>4.7 Implementing the model</font>"
      ],
      "metadata": {
        "id": "nwPV--pjegWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 20\n",
        "t_start = time.time()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for batch_idx, batch in enumerate(train_dataloader):\n",
        "        samples, labels = batch\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = cnn_model(samples)\n",
        "        loss = criterion_focal(y_pred, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Zero the gradients after updating\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Calculate training accuracy\n",
        "        _, predicted = torch.max(y_pred.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print training accuracy after each epoch\n",
        "    train_accuracy = correct_train / total_train\n",
        "    print(f'Epoch {epoch + 1}/{n_epochs}, Loss: {loss.item():.4f}, Training Accuracy: {train_accuracy * 100:.2f}%')\n",
        "\n",
        "t_end = time.time()\n",
        "print('Total training time:', t_end - t_start)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f5a725-4275-4c7d-ddd0-8a0375a22618",
        "id": "-4RFwlntJguq"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.3203, Training Accuracy: 53.17%\n",
            "Epoch 2/20, Loss: 0.3308, Training Accuracy: 66.01%\n",
            "Epoch 3/20, Loss: 0.1374, Training Accuracy: 80.62%\n",
            "Epoch 4/20, Loss: 0.0571, Training Accuracy: 91.70%\n",
            "Epoch 5/20, Loss: 0.0156, Training Accuracy: 96.21%\n",
            "Epoch 6/20, Loss: 0.0077, Training Accuracy: 98.96%\n",
            "Epoch 7/20, Loss: 0.0055, Training Accuracy: 99.49%\n",
            "Epoch 8/20, Loss: 0.0093, Training Accuracy: 99.84%\n",
            "Epoch 9/20, Loss: 0.0009, Training Accuracy: 99.96%\n",
            "Epoch 10/20, Loss: 0.0002, Training Accuracy: 100.00%\n",
            "Epoch 11/20, Loss: 0.0002, Training Accuracy: 100.00%\n",
            "Epoch 12/20, Loss: 0.0001, Training Accuracy: 100.00%\n",
            "Epoch 13/20, Loss: 0.0001, Training Accuracy: 100.00%\n",
            "Epoch 14/20, Loss: 0.0001, Training Accuracy: 100.00%\n",
            "Epoch 15/20, Loss: 0.0000, Training Accuracy: 100.00%\n",
            "Epoch 16/20, Loss: 0.0000, Training Accuracy: 100.00%\n",
            "Epoch 17/20, Loss: 0.0000, Training Accuracy: 100.00%\n",
            "Epoch 18/20, Loss: 0.0000, Training Accuracy: 100.00%\n",
            "Epoch 19/20, Loss: 0.0000, Training Accuracy: 100.00%\n",
            "Epoch 20/20, Loss: 0.0000, Training Accuracy: 100.00%\n",
            "Total training time: 1802.8344304561615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='cyan'>4.8 Evaluating on test set</font>"
      ],
      "metadata": {
        "id": "IqQf5ysQen4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize variables for accuracy calculation on the test set\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "cnn_model.eval()\n",
        "\n",
        "# Iterate over the test set\n",
        "with torch.no_grad():\n",
        "    for batch_idx, batch in enumerate(test_dataloader):\n",
        "        samples, labels = batch\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = cnn_model(samples)\n",
        "\n",
        "        # Calculate test accuracy\n",
        "        _, predicted = torch.max(y_pred.data, 1)\n",
        "        total_test += labels.size(0)\n",
        "        correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "# Print test accuracy\n",
        "test_accuracy = correct_test / total_test\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTtcPgCwJmzK",
        "outputId": "9e709666-a8e5-44b7-a040-c06ab342acbe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uxM9DsqbU9WN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}